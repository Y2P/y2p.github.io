[{"authors":["admin"],"categories":null,"content":"I am was a PhD student in the GAIA team of GIPSA Lab under the supervision of Nicolas Tremblay, Simon Barthelmé and Pierre-Olivier Amblard. In my thesis, I am working on Monte Carlo algorithms for linear algebra based on a particular stochastic process on graphs, called random spanning forests.\nBreaking News! I defended my thesis on 15 November 2022. See here for more details.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://y2p.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am was a PhD student in the GAIA team of GIPSA Lab under the supervision of Nicolas Tremblay, Simon Barthelmé and Pierre-Olivier Amblard. In my thesis, I am working on Monte Carlo algorithms for linear algebra based on a particular stochastic process on graphs, called random spanning forests.\nBreaking News! I defended my thesis on 15 November 2022. See here for more details.","tags":null,"title":"Yusuf Yigit PILAVCI","type":"authors"},{"authors":["Yusuf Yigit PILAVCI"],"categories":null,"content":"","date":1668470400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668470400,"objectID":"1a0d495537dfaebb4468e692cfa46898","permalink":"https://y2p.github.io/publication/phdthesis/","publishdate":"2022-11-15T00:00:00Z","relpermalink":"/publication/phdthesis/","section":"publication","summary":"An extensive range of problems in machine learning deals with data structured over networks/graphs. The examples vary from drug discovery to traffic forecasting,  social network analysis to recommender systems, or epidemic analysis to natural language processing. Along with the exploding size and number of data, a big chunk of the proposed algorithms has focused on analyzing, representing and leveraging the network structures in the last decades. In many of them, the graph Laplacian is the central object. They are notable matrix representations of graphs that relate to various aspects. For example, by analyzing the Laplacian algebraically, one can measure the connectivity, count the number of spanning trees or generate a visualization of a graph. Further examples can be found in the problems of node clustering, graph sparsification, signal processing on graphs and many more. However, the algebraic analysis of Laplacian can be frustratingly time-consuming if the graph consists of a large number of nodes. Despite many numerical tools specialized for the graph Laplacian, in certain cases, the computational time remains one of the main issues.\nRandom spanning forests (RSFs), a random process on graphs, is a probabilistic tool for analyzing graphs with strong links with the Laplacian. In a nutshell, RSFs provide meaningful random sketches (spanning forests) of the graph to analyze some properties of interest. These sketches are cheap to obtain by a variant of Wilson's algorithm. Moreover, by only looking at a few of them, one can deduce significant statistical and/or algebraic information on the overall graph. The existing applications of RSFs, including graph wavelet analysis, semi-supervised learning on graphs or centrality analysis, show that RSFs provide useful information while binding diverse aspects of graphs.\nIn this manuscript, we present ways of leveraging the rich connections between RSFs and the graph Laplacian to speed up the algebraic analysis. In doing so, we propose randomized algorithms to approximate several quantities of interest, such as the regularized inverse of the Laplacian or effective resistances. Interestingly, these quantities are required in a wide range of applications on graphs, including graph signal filtering, hyper-parameter tuning, graph-based optimization and sparsification. We illustrate these methods on real-life networks and compare them with state-of-the-art methods. ","tags":null,"title":"Wilson's Algorithm for Randomized Linear Algebra","type":"publication"},{"authors":["Yusuf Yigit PILAVCI","Pierre-Olivier Amblard","Simon Barthelme","Nicolas Tremblay"],"categories":null,"content":"","date":1662422400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662422400,"objectID":"aa35ad451b6c438cad6da141a30655d7","permalink":"https://y2p.github.io/publication/2022mar/","publishdate":"2022-09-06T00:00:00Z","relpermalink":"/publication/2022mar/","section":"publication","summary":"The trace $\\textit{tr}(q(\\mathsf{L} + q\\mathsf{I})^{-1})$, where $\\mathsf{L}$ is a symmetric diagonally dominant matrix, is the quantity of interest in some machine learning problems. However, its direct computation is impractical if the matrix size is large. State-of-the-art methods include Hutchinson's estimator combined with iterative solvers, as well as the estimator based on random spanning forests (a random process on graphs). In this work, we show two ways of improving the forest-based estimator via well-known variance reduction techniques, namely control variates and stratified sampling. Implementing these techniques is easy, and provides substantial variance reduction, yielding comparable or better performance relative to state-of-the-art algorithms.","tags":null,"title":"Variance Reduction for Inverse Trace Estimation via Random Spanning Forests","type":"publication"},{"authors":["Yusuf Yigit PILAVCI","Pierre-Olivier Amblard","Simon Barthelme","Nicolas Tremblay"],"categories":null,"content":"","date":1661731200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661731200,"objectID":"3282d497d9b2f26db92830e0810b9a8a","permalink":"https://y2p.github.io/publication/2021oct/","publishdate":"2022-08-29T00:00:00Z","relpermalink":"/publication/2021oct/","section":"publication","summary":"Large dimensional least-squares and regularised least-squares problems are expensive to solve. There exist many approximate techniques, some deterministic (like conjugate gradient), some stochastic (like stochastic gradient descent). Among the latter, a new class of techniques uses Determinantal Point Processes (DPPs) to produce unbiased estimators of the solution. In particular, they can be used to perform Tikhonov regularization on graphs using random spanning forests, a specific DPP. While the unbiasedness of these algorithms is attractive, their variance can be high. We show here that variance can be reduced by combining the stochastic estimator with a deterministic gradient-descent step, while keeping the property of unbiasedness. We apply this technique to Tikhonov regularization on graphs, where the reduction in variance is found to be substantial at very small extra cost.","tags":null,"title":"Variance reduction in stochastic methods for large-scale regularised least-squares problems","type":"publication"},{"authors":["Yusuf Yigit PILAVCI","Pierre-Olivier Amblard","Simon Barthelme","Nicolas Tremblay"],"categories":null,"content":"","date":1622160000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622160000,"objectID":"5ed777dfb9c82457e2b09b1c598f277b","permalink":"https://y2p.github.io/publication/2020nov/","publishdate":"2021-05-28T00:00:00Z","relpermalink":"/publication/2020nov/","section":"publication","summary":"Novel Monte Carlo estimators are proposed to solve both the Tikhonov regularization (TR) and the interpolation problems on graphs. These estimators are based on random spanning forests (RSF), the theoretical properties of which enable to analyze the estimators' theoretical mean and variance. We also show how to perform hyperparameter tuning for these RSF-based estimators. TR is a component in many well-known algorithms, and we show how the proposed estimators can be easily adapted to avoid expensive intermediate steps in generalized semi-supervised learning, label propagation, Newton's method and iteratively reweighted least squares. In the experiments, we illustrate the proposed methods on several problems and provide observations on their run time.","tags":null,"title":"Graph Tikhonov Regularization and Interpolation via Random Spanning Forests","type":"publication"},{"authors":["Yusuf Yigit PILAVCI","Pierre-Olivier Amblard","Simon Barthelme","Nicolas Tremblay"],"categories":null,"content":"","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588291200,"objectID":"5a8efee0778b927ebd7cb3319f139ffa","permalink":"https://y2p.github.io/publication/2020may/","publishdate":"2020-05-01T00:00:00Z","relpermalink":"/publication/2020may/","section":"publication","summary":"Another facet of the elegant link between random processes on graphs and Laplacian-based numerical linear algebra is uncovered: based on random spanning forests, novel Monte-Carlo estimators for graph signal smoothing are proposed. These random forests are sampled efficiently via a variant of Wilson's algorithm --in time linear in the number of edges. The theoretical variance of the proposed estimators are analyzed, and their application to several problems are considered, such as Tikhonov denoising of graph signals or semi-supervised learning for node classification on graphs.","tags":null,"title":"Smoothing graph signals via random spanning forests","type":"publication"},{"authors":["Yusuf Yigit PILAVCI","Eylem Tugce Guneyi","Cemil Cengiz","Elif Vural"],"categories":null,"content":"","date":1572566400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572566400,"objectID":"dd08346b807e96eda34432d0d89aa99c","permalink":"https://y2p.github.io/publication/2019nov/","publishdate":"2019-11-01T00:00:00Z","relpermalink":"/publication/2019nov/","section":"publication","summary":"In this paper we propose a domain adaptation algorithm designed for graph domains. Given a source graph with many labeled nodes and a target graph with few or no labeled nodes, we aim to estimate the target labels by making use of the similarity between the characteristics of the variation of the label functions on the two graphs. Our assumption about the source and the target domains is that the local behaviour of the label function, such as its spread and speed of variation on the graph, bears resemblance between the two graphs. We estimate the unknown target labels by solving an optimization problem where the label information is transferred from the source graph to the target graph based on the prior that the projections of the label functions onto localized graph bases be similar between the source and the target graphs. In order to efficiently capture the local variation of the label functions on the graphs, spectral graph wavelets are used as the graph bases. Experimentation on various data sets shows that the proposed method yields quite satisfactory classification accuracy compared to reference domain adaptation methods","tags":null,"title":"Graph Domain Adaptation with Localized Graph Signal Representations","type":"publication"},{"authors":["Yusuf Yigit PILAVCI","Nicolas Farrugia"],"categories":null,"content":"","date":1556668800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556668800,"objectID":"ae44f1864c1bc79571c472e849095179","permalink":"https://y2p.github.io/publication/2019may/","publishdate":"2019-05-01T00:00:00Z","relpermalink":"/publication/2019may/","section":"publication","summary":"Graph Signal Processing has become a very useful framework for signal operations and representations defined on irregular domains. Exploiting transformations that are defined on graph models can be highly beneficial when the graph encodes relationships between signals. In this work, we present the benefits of using Spectral Graph Wavelet Transform (SGWT) as a feature extractor for machine learning on brain graphs. First, we consider a synthetic regression problem in which the smooth graph signals are generated as input with additive noise, and the target is derived from the input without noise. This enables us to optimize the spectrum coverage using different wavelet shapes. Finally, we present the benefits obtained by SGWT on a functional Magnetic Resonance Imaging (fMRI) open dataset on human subjects, with several graphs and wavelet shapes, by demonstrating significant performance improvements compared to the state of the art.","tags":null,"title":"Spectral graph wavelet transform as feature extractor for machine learning in neuroimaging","type":"publication"},{"authors":["Mehmet Turan","Yusuf Yigit PILAVCI","Ipek Ganiyusufoglu","Helder Araujo","Ender Konukoglu","Metin Sitti"],"categories":null,"content":"","date":1512086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512086400,"objectID":"b4284648e2c3953c250e033729a15e39","permalink":"https://y2p.github.io/publication/2017dec/","publishdate":"2017-12-01T00:00:00Z","relpermalink":"/publication/2017dec/","section":"publication","summary":"","tags":null,"title":"Sparse-then-dense alignment-based 3d map reconstruction method for endoscopic capsule robots","type":"publication"}]